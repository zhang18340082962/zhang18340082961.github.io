{"title":"python常用功能代码整理，持续更新","uid":"3b7fc023aaa69e49fca460e6ff5152b5","slug":"python常用功能代码整理，持续更新","date":"2022-06-08T08:01:27.000Z","updated":"2022-06-19T04:54:35.508Z","comments":true,"path":"api/articles/python常用功能代码整理，持续更新.json","keywords":null,"cover":null,"content":"<p>部分参考，实测后有改动<br><a href=\"https://mp.weixin.qq.com/s/A0NYVPaNclMkKgie2swClw\">https://mp.weixin.qq.com/s/A0NYVPaNclMkKgie2swClw</a></p>\n<h1 id=\"本地文件整理-将本地多个-CSV-文件整合成一个文件\"><a href=\"#本地文件整理-将本地多个-CSV-文件整合成一个文件\" class=\"headerlink\" title=\"本地文件整理   将本地多个 CSV 文件整合成一个文件\"></a>本地文件整理   将本地多个 CSV 文件整合成一个文件</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import pandas as pd\nimport os\n\ndf_list &#x3D; []\nfor i in os.listdir():\n    if &quot;csv&quot; in i:\n        day &#x3D; i.split(&#39;.&#39;)[0].split(&#39;_&#39;)[-1]\n        df &#x3D; pd.read_csv(i)\n        df[&#39;day&#39;] &#x3D; day\n        df_list.append(df)\ndf &#x3D; pd.concat(df_list, axis&#x3D;0)\ndf.to_csv(&quot;total.txt&quot;, index&#x3D;0)</code></pre>\n\n<h1 id=\"多线程代码\"><a href=\"#多线程代码\" class=\"headerlink\" title=\"多线程代码\"></a>多线程代码</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import threading\nimport time\n\nexitFlag &#x3D; 0\n\nclass myThread (threading.Thread):\n    def __init__(self, threadID, name, delay):\n        threading.Thread.__init__(self)\n        self.threadID &#x3D; threadID\n        self.name &#x3D; name\n        self.delay &#x3D; delay\n    def run(self):\n        print (&quot;开始线程：&quot; + self.name)\n        print_time(self.name, self.delay, 5)\n        print (&quot;退出线程：&quot; + self.name)\n\ndef print_time(threadName, delay, counter):\n    while counter:\n        if exitFlag:\n            threadName.exit()\n        time.sleep(delay)\n        print (&quot;%s: %s&quot; % (threadName, time.ctime(time.time())))\n        counter -&#x3D; 1\n\n# 创建新线程\nthread1 &#x3D; myThread(1, &quot;Thread-1&quot;, 1)\nthread2 &#x3D; myThread(2, &quot;Thread-2&quot;, 2)\n\n# 开启新线程\nthread1.start()\nthread2.start()\nthread1.join()\nthread2.join()\nprint (&quot;退出主线程&quot;)</code></pre>\n\n<h1 id=\"异步编程代码-异步爬取网站\"><a href=\"#异步编程代码-异步爬取网站\" class=\"headerlink\" title=\"异步编程代码  异步爬取网站\"></a>异步编程代码  异步爬取网站</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import asyncio\nimport aiohttp\nimport aiofiles\n\nasync def get_html(session, url):\n    try:\n        async with session.get(url&#x3D;url, timeout&#x3D;8) as resp:\n            if not resp.status &#x2F;&#x2F; 100 &#x3D;&#x3D; 2:\n                print(resp.status)\n                print(&quot;爬取&quot;, url, &quot;出现错误&quot;)\n            else:\n                resp.encoding &#x3D; &#39;utf-8&#39;\n                text &#x3D; await resp.text()\n                return text\n    except Exception as e:\n        print(&quot;出现错误&quot;, e)\n        await get_html(session, url)\n        #使用异步请求之后，对应的文件保存也需要使用异步，即是一处异步，处处异步\nasync def download(title_list, content_list):\n    async with aiofiles.open(&#39;&#123;&#125;.txt&#39;.format(title_list[0]), &#39;a&#39;,\n                             encoding&#x3D;&#39;utf-8&#39;) as f:\n        await f.write(&#39;&#123;&#125;&#39;.format(str(content_list)))\n</code></pre>\n<h1 id=\"requests-库调用\"><a href=\"#requests-库调用\" class=\"headerlink\" title=\"requests 库调用\"></a>requests 库调用</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import requests\n\n#发送 GET 请求\nheaders &#x3D; &#123;\n    &#39;user-agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;96.0.4664.110 Safari&#x2F;537.36&#39;,\n  &#39;cookie&#39;: &#39;some_cookie&#39;\n&#125;\nresponse &#x3D; requests.request(&quot;GET&quot;, url, headers&#x3D;headers)\n#发送 POST 请求\nimport requests\n\npayload&#x3D;&#123;&#125;\nfiles&#x3D;[]\nheaders &#x3D; &#123;\n    &#39;user-agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;96.0.4664.110 Safari&#x2F;537.36&#39;,\n  &#39;cookie&#39;: &#39;some_cookie&#39;\n&#125;\nresponse &#x3D; requests.request(&quot;POST&quot;, url, headers&#x3D;headers, data&#x3D;payload, files&#x3D;files)\n\n\n#保存数据到CSV\nimport os\ndef save_data(data, date):\n    if not os.path.exists(r&#39;2021_data_%s.csv&#39; % date):\n        with open(&quot;2021_data_%s.csv&quot; % date, &quot;a+&quot;, encoding&#x3D;&#39;utf-8&#39;) as f:\n            f.write(&quot;标题,热度,时间,url\\n&quot;)\n            for i in data:\n                title &#x3D; i[&quot;title&quot;]\n                extra &#x3D; i[&quot;extra&quot;]\n                time &#x3D; i[&#39;time&#39;]\n                url &#x3D; i[&quot;url&quot;]\n                row &#x3D; &#39;&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;&#39;.format(title,extra,time,url)\n                f.write(row)\n                f.write(&#39;\\n&#39;)\n    else:\n        with open(&quot;2021_data_%s.csv&quot; % date, &quot;a+&quot;, encoding&#x3D;&#39;utf-8&#39;) as f:\n            for i in data:\n                title &#x3D; i[&quot;title&quot;]\n                extra &#x3D; i[&quot;extra&quot;]\n                time &#x3D; i[&#39;time&#39;]\n                url &#x3D; i[&quot;url&quot;]\n                row &#x3D; &#39;&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;&#39;.format(title,extra,time,url)\n                f.write(row)\n                f.write(&#39;\\n&#39;)</code></pre>\n\n<h1 id=\"IP代理池搭建\"><a href=\"#IP代理池搭建\" class=\"headerlink\" title=\"IP代理池搭建\"></a>IP代理池搭建</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import requests # python基础爬虫库\nfrom lxml import etree # 可以将网页转换为Elements对象\nimport time # 防止爬取过快可以睡眠一秒\n\n# 第一步：构造主页url地址，发送请求获取响应\n# 第二步：解析数据，将数据分组\n# 第三步：将数组的数据提取出来\n# 第四步：检测代理IP的可用性\n# 第五步：保存到文件中\n# https:&#x2F;&#x2F;blog.csdn.net&#x2F;yuan2019035055&#x2F;article&#x2F;details&#x2F;121334216\n\nclass daili():\n\n    # 1.发送请求，获取响应\n    def send_request(self, page):\n        print(&quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;正在抓取第&#123;&#125;页&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;.format(page))\n        # 目标网页，添加headers参数\n        base_url &#x3D; &#39;https:&#x2F;&#x2F;www.kuaidaili.com&#x2F;free&#x2F;inha&#x2F;&#123;&#125;&#x2F;&#39;.format(page)\n        headers &#x3D; &#123;\n            &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;95.0.4638.69 Safari&#x2F;537.36&#39;&#125;\n\n        # 发送请求：模拟浏览器发送请求，获取响应数据\n        response &#x3D; requests.get(base_url, headers&#x3D;headers)\n        data &#x3D; response.content.decode()\n        time.sleep(1)\n\n        return data\n\n    # 2.解析数据\n    def parse_data(self, data):\n\n        # 数据转换\n        html_data &#x3D; etree.HTML(data)\n        # 分组数据\n        parse_list &#x3D; html_data.xpath(&#39;&#x2F;&#x2F;table[@class&#x3D;&quot;table table-bordered table-striped&quot;]&#x2F;tbody&#x2F;tr&#39;)\n        return parse_list\n\n    # 4.检测代理IP\n    def check_ip(self, proxies_list):\n        headers &#x3D; &#123;\n            &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;95.0.4638.69 Safari&#x2F;537.36&#39;&#125;\n\n        can_use &#x3D; []\n        for proxies in proxies_list:\n            try:\n                response &#x3D; requests.get(&#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;&#39;, headers&#x3D;headers, proxies&#x3D;proxies, timeout&#x3D;0.1)\n                if response.status_code &#x3D;&#x3D; 200:\n                    can_use.append(proxies)\n            except Exception as e:\n                print(e)\n        return can_use\n\n    # 5.保存到文件\n    def save(self, can_use):\n\n        file &#x3D; open(&#39;..\\data\\IP.txt&#39;, &#39;w&#39;)\n        for i in range(len(can_use)):\n            s &#x3D; str(can_use[i]) + &#39;\\n&#39;\n            file.write(s)\n        file.close()\n\n    # 实现主要逻辑\n    def run(self):\n        proxies_list &#x3D; []\n        # 实现翻页，我这里只爬取了四页（可以修改5所在的数字）\n        for page in range(1, 3):\n            data &#x3D; self.send_request(page)\n            parse_list &#x3D; self.parse_data(data)\n            # 3.获取数据\n            for tr in parse_list:\n                proxies_dict &#x3D; &#123;&#125;\n                http_type &#x3D; tr.xpath(&#39;.&#x2F;td[4]&#x2F;text()&#39;)\n                ip_num &#x3D; tr.xpath(&#39;.&#x2F;td[1]&#x2F;text()&#39;)\n                port_num &#x3D; tr.xpath(&#39;.&#x2F;td[2]&#x2F;text()&#39;)\n\n                http_type &#x3D; &#39; &#39;.join(http_type)\n                ip_num &#x3D; &#39; &#39;.join(ip_num)\n                port_num &#x3D; &#39; &#39;.join(port_num)\n\n                proxies_dict[http_type] &#x3D; ip_num + &quot;:&quot; + port_num\n\n                proxies_list.append(proxies_dict)\n\n        print(&quot;获取到的代理IP数量：&quot;, len(proxies_list))\n\n        can_use &#x3D; self.check_ip(proxies_list)\n\n        print(&quot;能用的代理IP数量：&quot;, len(can_use))\n        print(&quot;能用的代理IP:&quot;, can_use)\n        self.save(can_use)\n\n\n\nif __name__ &#x3D;&#x3D; &quot;__main__&quot;:\n    dl &#x3D; daili()\n    dl.run()\n\n    # 从文件中随机取出一个IP去访问网址\n    import random\n    import requests\n    # 打开文件，换行读取\n    f&#x3D;open(&quot;..\\data\\IP.txt&quot;,&quot;r&quot;)\n    file &#x3D; f.readlines()\n\n    # 遍历并分别存入列表，方便随机选取IP\n    item &#x3D; []\n    for proxies in file:\n        proxies &#x3D; eval(proxies.replace(&#39;\\n&#39;,&#39;&#39;)) # 以换行符分割，转换为dict对象\n        item.append(proxies)\n\n    proxies &#x3D; random.choice(item)  # 随机选取一个IP\n\n    url &#x3D; &#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;&#39;\n    headers &#x3D; &#123;&#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;95.0.4638.69 Safari&#x2F;537.36&#39;&#125;\n\n    response &#x3D; requests.get(url,headers&#x3D;headers,proxies&#x3D;proxies)\n    print(response.status_code) # 输出状态码 200，表示访问成功\n    </code></pre>\n\n\n\n<h1 id=\"生成一段时间区间内的日期\"><a href=\"#生成一段时间区间内的日期\" class=\"headerlink\" title=\"生成一段时间区间内的日期\"></a>生成一段时间区间内的日期</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import pandas as pd\nprint([str(i) for i in pd.date_range(&#39;2020-02-03&#39;,&#39;2020-03-05&#39;,freq&#x3D;&quot;D&quot;).strftime(&quot;%Y-%m-%d&quot;).tolist()])</code></pre>\n\n<h1 id=\"获取过去-N-天的日期\"><a href=\"#获取过去-N-天的日期\" class=\"headerlink\" title=\"获取过去 N 天的日期\"></a>获取过去 N 天的日期</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import datetime\n\ndef get_nday_list(n):\n    before_n_days &#x3D; []\n    for i in range(1, n + 1)[::-1]:\n        before_n_days.append(str(datetime.date.today() - datetime.timedelta(days&#x3D;i)))\n    return before_n_days\n\na &#x3D; get_nday_list(30)\nprint(a)</code></pre>\n\n<h1 id=\"生成xmind\"><a href=\"#生成xmind\" class=\"headerlink\" title=\"生成xmind\"></a>生成xmind</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import xmind\n\nw &#x3D; xmind.load(&quot;test.xmind&quot;)\ns1 &#x3D; w.getPrimarySheet()  # 获取此工作表\ns1.setTitle(&quot;first sheet&quot;)  # 设置标题\na &#x3D; &#123;&quot;h1&quot;: &#39;Python 技术学习&#39;, &#39;h2&#39;: [&#39;Python基础&#39;, &#39;Python 爬虫&#39;],\n     &#39;h3&#39;: [[&#39;Python环境安装&#39;, &#39;Python基础语法&#39;, &#39;Python数据结构&#39;], [&#39;Python爬虫基础知识详解&#39;, &#39;Python爬虫相关模块详解&#39;]]&#125;\nr1 &#x3D; s1.getRootTopic()  # 获取此工作表的根主题\nr1.setTitle(a[&#39;h1&#39;])  # 设置标题\nc &#x3D; a[&#39;h2&#39;]\nc2 &#x3D; a[&#39;h3&#39;]\nfor i, val in enumerate(c):\n    print(i, val)\n    a &#x3D; &#39;b&#39; + str(i)\n    a &#x3D; r1.addSubTopic()\n    a.setTitle(val)  # 设置标题\n    for i2, val2 in enumerate(c2):\n        if i &#x3D;&#x3D; i2:\n            a2 &#x3D; &#39;b2&#39; + str(i)\n            a2 &#x3D; a.addSubTopic()\n            #        if isinstance(val, list):\n            for i3, val3 in enumerate(val2):\n                a3 &#x3D; &#39;b3&#39; + str(i3)\n                a3 &#x3D; a2.addSubTopic()\n                a3.setTitle(val3)\n\nxmind.save(w, &quot;Python_detail.xmind&quot;)</code></pre>\n<h1 id=\"【python】如何提取本机连接过的wifi密码（亲测好用\"><a href=\"#【python】如何提取本机连接过的wifi密码（亲测好用\" class=\"headerlink\" title=\"【python】如何提取本机连接过的wifi密码（亲测好用\"></a>【python】如何提取本机连接过的wifi密码（亲测好用</h1><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import subprocess\n# 获取wifi列表\noutput &#x3D; subprocess.run([&#39;netsh&#39;,&#39;wlan&#39;,&#39;show&#39;,&#39;profiles&#39;],capture_output &#x3D; True).stdout.decode(&#39;gbk&#39;).split(&#39;\\n&#39;)\nwifis &#x3D; [line.split(&#39;:&#39;)[1][1:-1] for line in output if &quot;所有用户配置文件&quot; in line]\n\n#查看每个wifi对应的密码\nfor wifi in wifis:\n    results &#x3D; subprocess.run([&#39;netsh&#39;,&#39;wlan&#39;,&#39;show&#39;,&#39;profile&#39;,wifi,&#39;key&#x3D;clear&#39;],capture_output &#x3D; True).stdout.decode(&#39;gbk&#39;,errors &#x3D; &#39;ignore&#39;).split(&#39;\\n&#39;)\n    results &#x3D; [line.split(&#39;:&#39;)[1][1:-1] for line in results if &quot;关键内容&quot; in line]\n    try:\n        print(f&#39;wifi账号：&#123;wifi&#125;，密码:&#123;results[0]&#125;&#39;)\n    except IndexError:\n        print(f&#39;wifi账号：&#123;wifi&#125;，密码:提取失败！&#39;)\n</code></pre>\n\n","text":"部分参考，实测后有改动https://mp.weixin.qq.com/s/A0NYVPaNclMkKgie2swClw 本地文件整理 将本地多个 CSV 文件整合成一个文件import pandas as pd import os df_list &#x3D; [] for i...","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"python","slug":"python","count":18,"path":"api/categories/python.json"}],"tags":[{"name":"python","slug":"python","count":1,"path":"api/tags/python.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E6%95%B4%E7%90%86-%E5%B0%86%E6%9C%AC%E5%9C%B0%E5%A4%9A%E4%B8%AA-CSV-%E6%96%87%E4%BB%B6%E6%95%B4%E5%90%88%E6%88%90%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6\"><span class=\"toc-text\">本地文件整理   将本地多个 CSV 文件整合成一个文件</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">多线程代码</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E4%BB%A3%E7%A0%81-%E5%BC%82%E6%AD%A5%E7%88%AC%E5%8F%96%E7%BD%91%E7%AB%99\"><span class=\"toc-text\">异步编程代码  异步爬取网站</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#requests-%E5%BA%93%E8%B0%83%E7%94%A8\"><span class=\"toc-text\">requests 库调用</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#IP%E4%BB%A3%E7%90%86%E6%B1%A0%E6%90%AD%E5%BB%BA\"><span class=\"toc-text\">IP代理池搭建</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%94%9F%E6%88%90%E4%B8%80%E6%AE%B5%E6%97%B6%E9%97%B4%E5%8C%BA%E9%97%B4%E5%86%85%E7%9A%84%E6%97%A5%E6%9C%9F\"><span class=\"toc-text\">生成一段时间区间内的日期</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E8%8E%B7%E5%8F%96%E8%BF%87%E5%8E%BB-N-%E5%A4%A9%E7%9A%84%E6%97%A5%E6%9C%9F\"><span class=\"toc-text\">获取过去 N 天的日期</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%94%9F%E6%88%90xmind\"><span class=\"toc-text\">生成xmind</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E3%80%90python%E3%80%91%E5%A6%82%E4%BD%95%E6%8F%90%E5%8F%96%E6%9C%AC%E6%9C%BA%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%9A%84wifi%E5%AF%86%E7%A0%81%EF%BC%88%E4%BA%B2%E6%B5%8B%E5%A5%BD%E7%94%A8\"><span class=\"toc-text\">【python】如何提取本机连接过的wifi密码（亲测好用</span></a></li></ol>","author":{"name":"弦好想断","slug":"blog-author","avatar":"/img/avatar.jpg","link":"/","description":"处女座男生，热爱技术、吉他、旅行。","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"python-flask疫情数据可视化","uid":"d36edaa00a28ef96e171ed217c165e70","slug":"python-flask疫情数据可视化","date":"2021-07-21T06:18:39.000Z","updated":"2022-06-22T16:04:40.973Z","comments":true,"path":"api/articles/python-flask疫情数据可视化.json","keywords":null,"cover":[],"text":"Flask是一个轻量级的web框架，看了https://www.bilibili.com/video/BV177411j7qJ 大佬的视频，做的一个疫情可视化项目,（电脑屏幕小看着有点拥挤。大屏展示还是挺好看的），热搜词云的数据找不到网站了，就弄了个表格；自己修改了一些部分，感兴...","link":"","photos":[],"count_time":{"symbolsCount":"8.8k","symbolsTime":"8 mins."},"categories":[{"name":"python","slug":"python","count":18,"path":"api/categories/python.json"}],"tags":[{"name":"数据分析","slug":"数据分析","count":15,"path":"api/tags/数据分析.json"}],"author":{"name":"弦好想断","slug":"blog-author","avatar":"/img/avatar.jpg","link":"/","description":"处女座男生，热爱技术、吉他、旅行。","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"python数据分析：xlwings操作excel","uid":"b183580f01b4c460a08090715fbc01f0","slug":"python数据分析：xlwings操作excel","date":"2022-01-16T11:16:09.000Z","updated":"2022-05-29T15:36:35.314Z","comments":true,"path":"api/articles/python数据分析：xlwings操作excel.json","keywords":null,"cover":null,"text":"xlwings是Python中操作Excel的一个第三方库，支持.xls读写，.xlsx读写，操作非常简单，功能也很强大xlwings与VBA的配合非常完美，你可以在python中调用VBA，也可以在VBA中使用python编程，这些通过xlwings都可以巧妙实现。先说装这个x...","link":"","photos":[],"count_time":{"symbolsCount":"3.5k","symbolsTime":"3 mins."},"categories":[{"name":"python","slug":"python","count":18,"path":"api/categories/python.json"}],"tags":[{"name":"数据分析","slug":"数据分析","count":15,"path":"api/tags/数据分析.json"}],"author":{"name":"弦好想断","slug":"blog-author","avatar":"/img/avatar.jpg","link":"/","description":"处女座男生，热爱技术、吉他、旅行。","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}